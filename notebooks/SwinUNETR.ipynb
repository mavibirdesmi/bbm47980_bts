{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f3d27d",
   "metadata": {},
   "source": [
    "Inspired from https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/swin_unetr_brats21_segmentation_3d.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc934863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nrrd\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6130620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd04f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "from monai.transforms.transform import Transform, MapTransform\n",
    "from monai.config import KeysCollection\n",
    "from monai.utils.enums import TransformBackends\n",
    "\n",
    "import torch\n",
    "\n",
    "def generate_sample_paths_from_json(\n",
    "    root_path : str\n",
    "):\n",
    "    config_path = os.path.join(\n",
    "        root_path,\n",
    "        \"data.json\"\n",
    "    )\n",
    "    with open(config_path, \"r\") as file:\n",
    "        config : Dict = json.load(file)\n",
    "    \n",
    "    sample_paths = []\n",
    "    for sample_id, sample_content in config.items():\n",
    "        mri_path = os.path.join(\n",
    "            root_path,\n",
    "            sample_id,\n",
    "            sample_content[\"image\"]\n",
    "        )\n",
    "        label_path = os.path.join(\n",
    "            root_path,\n",
    "            sample_id,\n",
    "            sample_content[\"label\"]\n",
    "        )\n",
    "        sample_paths.append({\n",
    "            \"image\" : mri_path,\n",
    "            \"label\" : label_path\n",
    "        })\n",
    "    \n",
    "    return sample_paths\n",
    "\n",
    "class ConvertToMultiChannelBasedOnBtsClasses (Transform):\n",
    "    \"\"\"\n",
    "    Converts 3 dimensional label to 4 dimensional based on the Brain Tumor\n",
    "    Classification (BTS) dataset\n",
    "    label 1 is the brain (gray matter)\n",
    "    label 2 is the tumour\n",
    "    \"\"\"\n",
    "    backend = [TransformBackends.TORCH]\n",
    "\n",
    "    def __call__ (self, img : torch.Tensor):\n",
    "        # if img has channel dim, squeeze it\n",
    "        if img.ndim == 4 and img.shape[0] == 1:\n",
    "            img = img.squeeze(0)\n",
    "        \n",
    "        result = [img == 1, img == 2]\n",
    "        \n",
    "        return torch.stack(result, dim=0)\n",
    "\n",
    "\n",
    "class ConvertToMultiChannelBasedOnBtsClassesd (MapTransform):\n",
    "    \"\"\"\n",
    "    Dictionary based wrapper of ConvertToMultiChannelBasedOnBtsClasses\n",
    "    Converts 3 dimensional label to 4 dimensional based on the Brain Tumor\n",
    "    Classification (BTS) dataset\n",
    "    label 1 is the brain (gray matter)\n",
    "    label 2 is the tumour\n",
    "    \"\"\"\n",
    "\n",
    "    backend = ConvertToMultiChannelBasedOnBtsClasses.backend\n",
    "\n",
    "    def __init__(self, keys: KeysCollection, allow_missing_keys: bool = False):\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.converter = ConvertToMultiChannelBasedOnBtsClasses()\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        data_dict = dict(data)\n",
    "        for key in self.key_iterator(data_dict):\n",
    "            data_dict[key] = self.converter(data_dict[key])\n",
    "        \n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42628d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "shuffle = True\n",
    "\n",
    "roi = (128, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556571d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai import data\n",
    "from monai import transforms\n",
    "from monai.data.utils import list_data_collate, collate_meta_tensor\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# get paths by using the json file\n",
    "sample_paths = generate_sample_paths_from_json(root_path)\n",
    "\n",
    "\n",
    "def add_new_axis(data):\n",
    "    data[\"image\"] = data[\"image\"][None, ...]\n",
    "    data[\"label\"] = data[\"label\"][None, ...]\n",
    "    return data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "    \n",
    "# create transformations\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.LoadImaged(keys=[\"image\", \"label\"], image_only=True),\n",
    "    add_new_axis,\n",
    "    transforms.Resized(keys=[\"image\", \"label\"], spatial_size=(200, 200, 200)),\n",
    "    ConvertToMultiChannelBasedOnBtsClassesd(keys=[\"label\"]),\n",
    "    # transforms.CropForegroundd(\n",
    "    #     keys=[\"image\", \"label\"],\n",
    "    #     source_key=\"image\",\n",
    "    #     # k_divisible=[roi[0], roi[1], roi[2]],\n",
    "    # ),\n",
    "    # transforms.RandSpatialCropd(\n",
    "    #     keys=[\"image\", \"label\"],\n",
    "    #     roi_size=[roi[0], roi[1], roi[2]],\n",
    "    #     random_size=False,\n",
    "    # ),\n",
    "    # transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "    # transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "    # transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "    # transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    # transforms.RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "    # transforms.RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = data.Dataset(\n",
    "    data=sample_paths,\n",
    "    transform=img_transforms,\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    elem = batch[0]\n",
    "    coll = {}\n",
    "    \n",
    "    for key in elem:\n",
    "        data_for_batch = tuple(torch.as_tensor(d[key]) for d in batch)\n",
    "        coll[key] = torch.stack(data_for_batch, dim=0)\n",
    "    \n",
    "    return coll\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4d7f0",
   "metadata": {},
   "source": [
    "### Check data shape and visualize from data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 100\n",
    "\n",
    "img = x[\"image\"][0][0]\n",
    "\n",
    "label = x[\"label\"][0][0] + 2 * x[\"label\"][0][1]\n",
    "\n",
    "print(f\"image shape: {img.shape}, label shape: {label.shape}\")\n",
    "plt.figure(\"image\", (18, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(img[:, :, slice_num], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, slice_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e26775",
   "metadata": {},
   "source": [
    "### Check data shape and visualize from nrrd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff006dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 78\n",
    "\n",
    "img, _ = nrrd.read(f\"{root_path}/ahmet_timur_label/21 t1_mprage_tra_p2_iso.nrrd\")\n",
    "label, _ = nrrd.read(f\"{root_path}/ahmet_timur_label/transformed_label.nrrd\")\n",
    "print(f\"image shape: {img.shape}, label shape: {label.shape}\")\n",
    "plt.figure(\"image\", (18, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(img[:, :, slice_num], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, slice_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d17b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "from monai.utils.enums import MetricReduction\n",
    "from monai.data import decollate_batch\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b3304",
   "metadata": {},
   "source": [
    "### Setup data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "directory = \"/home/vedatb/senior-project/bbm47980_bts/notebooks/swinunetr-checkpoints\"\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089f55a",
   "metadata": {},
   "source": [
    "### Setup average meter, fold reader, checkpoint save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529af972",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = np.where(self.count > 0, self.sum / self.count, self.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, epoch, filename=\"model.pt\", best_acc=0, dir_add=root_dir):\n",
    "    state_dict = model.state_dict()\n",
    "    save_dict = {\"epoch\": epoch, \"best_acc\": best_acc, \"state_dict\": state_dict}\n",
    "    filename = os.path.join(dir_add, filename)\n",
    "    torch.save(save_dict, filename)\n",
    "    print(\"Saving checkpoint\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7b32c",
   "metadata": {},
   "source": [
    "### Setup device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b56cf4",
   "metadata": {},
   "source": [
    "### SwinUNETR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb15d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinUNETR(\n",
    "    img_size=roi,\n",
    "    in_channels=1, # t1 images,\n",
    "    out_channels=2, # brain and tumor\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9f9b5",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sw_batch_size = 2\n",
    "fold = 1\n",
    "infer_overlap = 0.5\n",
    "max_epochs = 100\n",
    "val_every = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08de55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causes cuDNN to benchmark multiple convolution algorithms and select the fastest.\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d50e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = DiceLoss(to_onehot_y=False, sigmoid=True)\n",
    "post_sigmoid = Activations(sigmoid=True)\n",
    "post_pred = AsDiscrete(argmax=False, threshold=0.5)\n",
    "dice_acc = DiceMetric(include_background=True, reduction=MetricReduction.MEAN_BATCH, get_not_nans=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5317d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inferer = partial(\n",
    "    sliding_window_inference,\n",
    "    roi_size=roi,\n",
    "    sw_batch_size=sw_batch_size,\n",
    "    predictor=model,\n",
    "    overlap=infer_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a46a7f",
   "metadata": {},
   "source": [
    "### Define Train and Validation Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af66c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    loss_function,\n",
    "):\n",
    "    model.train()\n",
    "    run_loss = AverageMeter()\n",
    "    start_time = time.time()\n",
    "    for idx, batch_data in enumerate(loader):\n",
    "        data, target = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "        logits = model(data)\n",
    "        loss = loss_function(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        run_loss.update(loss.item(), n=batch_size)\n",
    "        print(\n",
    "            \"Epoch {}/{} {}/{}\".format(epoch, max_epochs, idx, len(loader)),\n",
    "            \"Loss: {:.4f}\".format(run_loss.avg),\n",
    "            \"Time {:.2f}s\".format(time.time() - start_time),\n",
    "        )\n",
    "        wandb.log({\"loss\": run_loss})\n",
    "        start_time = time.time()\n",
    "    return run_loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1862fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    epoch,\n",
    "    acc_func,\n",
    "    model_inferer=None,\n",
    "    post_sigmoid=None,\n",
    "    post_pred=None,\n",
    "):\n",
    "    model.eval()\n",
    "    run_acc = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch_data in enumerate(loader):\n",
    "            data, target = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "            logits = model_inferer(data)\n",
    "            val_labels_list = decollate_batch(target)\n",
    "            val_outputs_list = decollate_batch(logits)\n",
    "            val_output_convert = [\n",
    "                post_pred(post_sigmoid(val_pred_tensor))\n",
    "                for val_pred_tensor in val_outputs_list\n",
    "            ]\n",
    "            acc_func.reset()\n",
    "            acc_func(y_pred=val_output_convert, y=val_labels_list)\n",
    "            acc, not_nans = acc_func.aggregate()\n",
    "            run_acc.update(acc.cpu().numpy(), n=not_nans.cpu().numpy())\n",
    "            dice_brain = run_acc.avg[0]\n",
    "            dice_tumor = run_acc.avg[1]\n",
    "            print(\n",
    "                \"Val {}/{} {}/{}\".format(epoch, max_epochs, idx, len(loader)),\n",
    "                \", dice_brain:\",\n",
    "                dice_brain,\n",
    "                \", dice_tumor:\",\n",
    "                dice_tumor,\n",
    "            )\n",
    "            wandb.log({\"dice_brain\": dice_brain, \"dice_tumor\": dice_tumor})\n",
    "            \n",
    "    return run_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    loss_func,\n",
    "    acc_func,\n",
    "    scheduler,\n",
    "    model_inferer=None,\n",
    "    start_epoch=0,\n",
    "    post_sigmoid=None,\n",
    "    post_pred=None,\n",
    "):\n",
    "    val_acc_max = 0.0\n",
    "    dices_brain = []\n",
    "    dices_tumor = []\n",
    "    dices_avg = []\n",
    "    loss_epochs = []\n",
    "    trains_epoch = []\n",
    "    for epoch in range(start_epoch, max_epochs):\n",
    "        print(time.ctime(), \"Epoch:\", epoch)\n",
    "        epoch_time = time.time()\n",
    "        train_loss = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            epoch=epoch,\n",
    "            loss_function=loss_func,\n",
    "        )\n",
    "        print(\n",
    "            \"Final training  {}/{}\".format(epoch, max_epochs - 1),\n",
    "            \"Loss: {:.4f}\".format(train_loss),\n",
    "            \"Time {:.2f}s\".format(time.time() - epoch_time),\n",
    "        )\n",
    "\n",
    "        if (epoch + 1) % val_every == 0 or epoch == 0:\n",
    "            loss_epochs.append(train_loss)\n",
    "            trains_epoch.append(int(epoch))\n",
    "            epoch_time = time.time()\n",
    "            val_acc = val_epoch(\n",
    "                model,\n",
    "                val_loader,\n",
    "                epoch=epoch,\n",
    "                acc_func=acc_func,\n",
    "                model_inferer=model_inferer,\n",
    "                post_sigmoid=post_sigmoid,\n",
    "                post_pred=post_pred,\n",
    "            )\n",
    "            dice_brain = val_acc[0]\n",
    "            dice_tumor = val_acc[1]\n",
    "            val_avg_acc = np.mean(val_acc)\n",
    "            print(\n",
    "                \"Final validation stats {}/{}\".format(epoch, max_epochs - 1),\n",
    "                \", dice_brain:\",\n",
    "                dice_brain,\n",
    "                \", dice_tumor:\",\n",
    "                dice_tumor,\n",
    "                \", Dice_Avg:\",\n",
    "                val_avg_acc,\n",
    "                \", time {:.2f}s\".format(time.time() - epoch_time),\n",
    "            )\n",
    "            dices_brain.append(dice_brain)\n",
    "            dices_tumor.append(dice_tumor)\n",
    "            dices_avg.append(val_avg_acc)\n",
    "            if val_avg_acc > val_acc_max:\n",
    "                print(\"new best ({:.6f} --> {:.6f}). \".format(val_acc_max, val_avg_acc))\n",
    "                val_acc_max = val_avg_acc\n",
    "                save_checkpoint(\n",
    "                    model,\n",
    "                    epoch,\n",
    "                    best_acc=val_acc_max,\n",
    "                )\n",
    "            scheduler.step()\n",
    "    print(\"Training Finished !, Best Accuracy: \", val_acc_max)\n",
    "    return (\n",
    "        val_acc_max,\n",
    "        dices_brain,\n",
    "        dices_tumor,\n",
    "        dices_avg,\n",
    "        loss_epochs,\n",
    "        trains_epoch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66985b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "\n",
    "(val_acc_max, dices_brain, dices_tumor, dices_avg, loss_epochs, trains_epoch,) = trainer(\n",
    "    model=model,\n",
    "    train_loader=dataloader,\n",
    "    val_loader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=dice_loss,\n",
    "    acc_func=dice_acc,\n",
    "    scheduler=scheduler,\n",
    "    model_inferer=model_inferer,\n",
    "    start_epoch=start_epoch,\n",
    "    post_sigmoid=post_sigmoid,\n",
    "    post_pred=post_pred,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train completed, best average dice: {val_acc_max:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(trains_epoch, loss_epochs, color=\"red\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(trains_epoch, dices_avg, color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af504e5c",
   "metadata": {},
   "source": [
    "## Plot the Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff92ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Val Mean Dice Brain\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(trains_epoch, dices_brain, color=\"blue\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Val Mean Dice Tumor\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(trains_epoch, dices_tumor, color=\"brown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b2318",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc682f30",
   "metadata": {},
   "source": [
    "### Read test json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json_path = root_path\n",
    "test_paths = generate_sample_paths_from_json(test_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71abec9",
   "metadata": {},
   "source": [
    "### Create test dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231cf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        add_new_axis,\n",
    "        ConvertToMultiChannelBasedOnBtsClassesd(keys=\"label\"),\n",
    "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_ds = data.Dataset(data=test_paths, transform=test_transform)\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8811f55",
   "metadata": {},
   "source": [
    "### Load the best saved checkpoint and perform inference\n",
    "We select a single case from the validation set and perform inference to compare the model segmentation output with the corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02476a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"model.pt\"))[\"state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "model_inferer_test = partial(\n",
    "    sliding_window_inference,\n",
    "    roi_size=[roi[0], roi[1], roi[2]],\n",
    "    sw_batch_size=1,\n",
    "    predictor=model,\n",
    "    overlap=0.6,\n",
    ")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data in test_loader:\n",
    "        image = batch_data[\"image\"].cuda()\n",
    "        prob = torch.sigmoid(model_inferer_test(image))\n",
    "        seg = prob[0].detach().cpu().numpy()\n",
    "        seg = (seg > 0.5).astype(np.int8)\n",
    "        seg_out = np.zeros((seg.shape[1], seg.shape[2], seg.shape[3]))\n",
    "        seg_out[seg[0] == 1] = 1\n",
    "        seg_out[seg[1] == 1] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 67\n",
    "img, _ = nrrd.read(f\"{root_path}/ahmet_timur_label/21 t1_mprage_tra_p2_iso.nrrd\")\n",
    "label, _ = nrrd.read(f\"{root_path}/ahmet_timur_label/transformed_label.nrrd\")\n",
    "print(f\"image shape: {img.shape}, label shape: {label.shape}\")\n",
    "plt.figure(\"image\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(img[:, :, slice_num], cmap=\"gray\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, slice_num])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"segmentation\")\n",
    "plt.imshow(seg_out[:, :, slice_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 175\n",
    "img, _ = nrrd.read(f\"{root_path}/ahmet_timur_label/21 t1_mprage_tra_p2_iso.nrrd\")\n",
    "label, _ = nrrd.read(f\"{root_path}/ahmet_timur_label/transformed_label.nrrd\")\n",
    "print(f\"image shape: {img.shape}, label shape: {label.shape}\")\n",
    "plt.figure(\"image\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(img[:, :, slice_num], cmap=\"gray\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, slice_num])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"segmentation\")\n",
    "plt.imshow(seg_out[:, :, slice_num])\n",
    "a = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8eacfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_slice = img.shape[2]\n",
    "\n",
    "for slice_num in range(num_slice):\n",
    "    wandb.log({\n",
    "        \"Image\": wandb.Image(img[:, :, slice_num]),\n",
    "        \"Label\": wandb.Image(label[:, :, slice_num]),\n",
    "        \"Prediction\": wandb.Image(seg_out[:, :, slice_num])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2825a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
